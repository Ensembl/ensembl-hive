#########################################################################################################
#
# Some stored functions, views and procedures used in hive:
#


#### show hive progress for analyses (turned into a view to give extra flexibility) #####################
#
# Thanks to Greg Jordan for the idea and the original version
#
# Usage:
#       select * from progress;                                         # the whole table (may take ages to generate, depending on the size of your pipeline)
#       select * from progress where logic_name like 'family_blast%';   # only show family_blast-related analyses
#       select * from progress where retry_count>1;                     # only show jobs that have been tried more than once

CREATE OR REPLACE VIEW progress AS
    SELECT CONCAT(a.logic_name,'(',a.analysis_id,')') analysis_name_and_id,
            j.status,
            j.retry_count,
            CASE WHEN j.status IS NULL THEN 0 ELSE count(*) END cnt,
            job_id example_job_id
    FROM analysis a LEFT JOIN job j USING (analysis_id)
    GROUP BY a.analysis_id, j.status, j.retry_count
    ORDER BY a.analysis_id, j.status;


#### show LSF resource usage measured by lsf_report.pl script (won't show much if you haven't run the script)
#
# Usage:
#       select * from lsf_usage;                                                    # the whole table
#       select * from lsf_usage where analysis_name_and_id like 'family_blast%';    # filter by analysis_name pattern
#       select * from lsf_usage where rc_id=5;                                      # filter by specific rc_id

CREATE OR REPLACE VIEW lsf_usage AS
    SELECT CONCAT(logic_name,'(',analysis_id,')') analysis_name_and_id,
        rc_id, count(*) workers,
        min(mem), avg(mem), max(mem),
        min(swap), avg(swap), max(swap)
    FROM analysis
    JOIN analysis_stats USING(analysis_id)
    JOIN worker USING(analysis_id)
    LEFT JOIN lsf_report USING (process_id)
    GROUP BY analysis_id
    ORDER BY analysis_id;


#### a convenient view that also incorporates (otherwise redundant) analysis_id and logic_name ###########
#
# Usage:
#       select * from msg;
#       select * from msg where analysis_id=18;
#       select * from msg where logic_name like 'family_blast%';

CREATE OR REPLACE VIEW msg AS
    SELECT a.analysis_id, a.logic_name, m.*
    FROM job_message m
    JOIN job j USING (job_id)
    JOIN analysis a USING (analysis_id);


#### time an analysis or group of analyses (given by a name pattern) ######################################
# You'll get better precision when the analyses involved have been done or failed rather than still running.
#
# Usage:
#       call time_analysis('%');                # time the whole pipeline
#       call time_analysis('load_uniprot%');    # time the group of analyses dealing with loading Uniprot members
#       call time_analysis('mcl');              # time one specific analysis

DROP PROCEDURE IF EXISTS time_analysis;
CREATE PROCEDURE time_analysis(IN param_logic_name_pattern char(64))
READS SQL DATA
    SELECT
        (UNIX_TIMESTAMP(max(last_check_in))-UNIX_TIMESTAMP(min(born)))/60 AS measured_in_minutes,
        (UNIX_TIMESTAMP(max(last_check_in))-UNIX_TIMESTAMP(min(born)))/3600 AS measured_in_hours,
        (UNIX_TIMESTAMP(max(last_check_in))-UNIX_TIMESTAMP(min(born)))/3600/24 AS measured_in_days
        FROM worker JOIN analysis USING (analysis_id)
        WHERE logic_name like param_logic_name_pattern;


#### searches for a given string in job.input_id or analysis_data.data, and returns the  matching jobs.
#
# Thanks to Greg Jordan for the idea and the original version
#
# Usage:
#       call job_search('other_415');           # return all jobs whose input_id or analysis_data match the pattern

DROP PROCEDURE IF EXISTS job_search;
CREATE PROCEDURE job_search(IN srch CHAR(40))
READS SQL DATA
  SELECT
    a.analysis_id,
    a.logic_name,
    j.job_id AS job_id,
    j.status,
    j.retry_count,
    IFNULL(d.data, j.input_id) input_id
  FROM job j JOIN analysis a USING (analysis_id)
    LEFT JOIN analysis_data d ON j.input_id=concat('_ext_input_analysis_data_id ',d.analysis_data_id)
  WHERE j.input_id LIKE concat('%',srch,'%') OR d.data LIKE concat('%',srch,'%');


############## reset failed jobs for analysis #############################################
#
# Usage:
#       call reset_failed_jobs_for_analysis('load_uniprot');    # reset failed jobs of this particular analysis

DROP PROCEDURE IF EXISTS reset_failed_jobs_for_analysis;
CREATE PROCEDURE reset_failed_jobs_for_analysis(IN param_logic_name char(64))
MODIFIES SQL DATA
    UPDATE job j JOIN analysis a USING (analysis_id)
    SET j.status='READY', j.retry_count=0
    WHERE a.logic_name=param_logic_name
    AND   j.status='FAILED';


############## drop hive tables ###########################################################
#
# Usage:
#       call drop_hive_tables;      # just drop them all

DROP PROCEDURE IF EXISTS drop_hive_tables;
DELIMITER //
CREATE PROCEDURE drop_hive_tables()
MODIFIES SQL DATA
BEGIN
    DROP VIEW IF EXISTS msg, progress;
    DROP TABLE IF EXISTS monitor, analysis_stats_monitor, resource_description, analysis_data, job_file, dataflow_rule, analysis_ctrl_rule, analysis_stats, job_message, job, worker;
END; //
DELIMITER ;

