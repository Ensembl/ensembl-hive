/*

DESCRIPTION

    Some stored functions, views and procedures used in eHive


LICENSE

    Copyright [1999-2015] Wellcome Trust Sanger Institute and the EMBL-European Bioinformatics Institute
    Copyright [2016-2021] EMBL-European Bioinformatics Institute

    Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

         http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software distributed under the License
    is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and limitations under the License.

CONTACT

    Please subscribe to the Hive mailing list:  http://listserver.ebi.ac.uk/mailman/listinfo/ehive-users  to discuss Hive-related questions or to be notified of our updates

*/


-- show hive progress for analyses (turned into a view to give extra flexibility) ----------------
--
-- Thanks to Greg Jordan for the idea and the original version
--
-- Usage:
--       select * from progress;                                         # the whole table (may take ages to generate, depending on the size of your pipeline)
--       select * from progress where analysis_name_and_id like 'family_blast%';   # only show family_blast-related analyses
--       select * from progress where retry_count>1;                     # only show jobs that have been tried more than once

CREATE OR REPLACE VIEW progress AS
    SELECT CONCAT( a.logic_name, '(', a.analysis_id, ')') analysis_name_and_id,
        MIN(rc.name) resource_class,
        j.status,
        j.retry_count,
        CASE WHEN j.status IS NULL THEN 0 ELSE count(*) END cnt,
        MIN(job_id) example_job_id
    FROM        analysis_base a
    LEFT JOIN   job j USING (analysis_id)
    LEFT JOIN   resource_class rc ON (a.resource_class_id=rc.resource_class_id)
    GROUP BY a.analysis_id, j.status, j.retry_count
    ORDER BY a.analysis_id, j.status;


-- show the hierarchy of hive jobs (which analysis seeded jobs where) ----------------------------
--
-- Usage:
--       select * from job_hierarchy;                                         # the whole table (may take ages to generate, depending on the size of your pipeline)
--       select * from job_hierarchy where retry_count>1;                     # only show jobs that have been tried more than once

CREATE OR REPLACE VIEW job_hierarchy AS
	SELECT
		CONCAT(a1.logic_name, '(', a1.analysis_id, ')') AS analysis_name_and_id,
		CONCAT(a2.logic_name, '(', a2.analysis_id, ')') AS parent_analysis_name_and_id,
		j1.status AS status,
		j1.retry_count AS retry_count,
		COUNT(0) AS cnt,
		MIN(j1.job_id) AS example_job_id
	FROM
		job j1
		LEFT JOIN job j2 ON (j1.prev_job_id = j2.job_id)
		LEFT JOIN analysis_base a1 ON (j1.analysis_id = a1.analysis_id)
		LEFT JOIN analysis_base a2 ON (j2.analysis_id = a2.analysis_id)
	GROUP BY
		a1.logic_name,
		a2.logic_name,
		j1.status,
		j1.retry_count
	ORDER BY
		a1.analysis_id,
		a2.analysis_id,
		j1.retry_count;
DROP VIEW job_hierarchy;


-- a convenient view that also incorporates (otherwise redundant) analysis_id and logic_name ------------
--
-- Usage:
--       select * from msg;
--       select * from msg where analysis_id=18;
--       select * from msg where logic_name like 'family_blast%';

CREATE OR REPLACE VIEW msg AS
    SELECT a.analysis_id, a.logic_name, m.*
    FROM log_message m
    LEFT JOIN role USING (role_id)
    LEFT JOIN analysis_base a USING (analysis_id);


-- show the jobs with related semaphores -------
--
-- Usage:
--       select * from semaphore_job;

CREATE OR REPLACE VIEW semaphore_job AS
    SELECT
        job.job_id AS job_id,
        job.prev_job_id AS prev_job_id,
        job.analysis_id AS analysis_id,
        job.input_id AS input_id,
        job.param_id_stack AS param_id_stack,
        job.accu_id_stack AS accu_id_stack,
        job.role_id AS role_id,
        job.status AS status,
        job.retry_count AS retry_count,
        job.when_completed AS when_completed,
        job.runtime_msec AS runtime_msec,
        job.query_count AS query_count,
        semaphore.local_jobs_counter AS local_jobs_counter,
        semaphore.remote_jobs_counter AS remote_jobs_counter,
        semaphore.dependent_semaphore_url AS dependent_semaphore_url
    FROM job JOIN semaphore
    ON semaphore.dependent_job_id = job.job_id;


-- show statistics of Workers' real resource usage by analysis -------------------------------------------
--
-- Usage:
--       select * from resource_usage_stats;
--       select * from resource_usage_stats where logic_name like 'family_blast%';

CREATE OR REPLACE VIEW resource_usage_stats AS
    SELECT CONCAT(a.logic_name,'(',a.analysis_id,')') analysis,
           w.meadow_type,
           CONCAT(rc.name,'(',rc.resource_class_id,')') resource_class,
           u.exit_status,
           count(*) AS num_workers,
           min(mem_megs) AS min_mem_megs, round(avg(mem_megs),2) AS avg_mem_megs, max(mem_megs) AS max_mem_megs,
           round(min(cpu_sec/lifespan_sec),2) AS min_cpu_usage, round(avg(cpu_sec/lifespan_sec),2) AS avg_cpu_usage, round(max(cpu_sec/lifespan_sec),2) AS max_cpu_usage
    FROM resource_class rc
    JOIN analysis_base a USING(resource_class_id)
    LEFT JOIN role r USING(analysis_id)
    LEFT JOIN worker w USING(worker_id)
    LEFT JOIN worker_resource_usage u USING (worker_id)
    GROUP BY a.analysis_id, w.meadow_type, rc.resource_class_id, u.exit_status
    ORDER BY a.analysis_id, w.meadow_type, rc.resource_class_id, u.exit_status;


-- show the roles that are currently live (grouped by meadow_users, resource_classes and analyses) -------
--
-- Usage:
--       select * from live_roles;
--       select * from live_roles where resource_class_id=12;

CREATE OR REPLACE VIEW live_roles AS
    SELECT w.meadow_user, w.meadow_type, w.resource_class_id, rc.name resource_class_name, r.analysis_id, a.logic_name, count(*) AS num_workers
    FROM worker w
    JOIN role r USING(worker_id)
    LEFT JOIN resource_class rc ON w.resource_class_id=rc.resource_class_id
    LEFT JOIN analysis_base a USING(analysis_id)
    WHERE r.when_finished IS NULL
    GROUP BY w.meadow_user, w.meadow_type, w.resource_class_id, rc.name, r.analysis_id, a.logic_name;

-- show activity of beekeepers in this hive
--
-- Usage:
--       select * from beekeeper_activity;
--
--       -- Find beekeepers that may have disappeared
--       select * from beekeeper_activity
--       where cause_of_death is null
--       and is_overdue = 1

CREATE OR REPLACE VIEW beekeeper_activity AS
    SELECT b.beekeeper_id, b.meadow_user, b.meadow_host, b.sleep_minutes, b.loop_limit, b.is_blocked,
           b.cause_of_death, COUNT(*) AS loops_executed,
           MAX(lm.when_logged) AS last_heartbeat,
           IF(cause_of_death IS NULL, TIMEDIFF(now(), max(lm.when_logged)), NULL) AS time_since_last_heartbeat,
           IF(cause_of_death IS NULL, TIMEDIFF(SEC_TO_TIME(sleep_minutes * 60), TIMEDIFF(now(), max(lm.when_logged))) < 0, NULL) AS is_overdue
    FROM beekeeper b
    LEFT JOIN log_message lm
    ON b.beekeeper_id = lm.beekeeper_id
    GROUP BY b.beekeeper_id;

-- time an analysis or group of analyses (given by a name pattern) ----------------------------------------
--
-- Usage:
--       call time_analysis('%');                # time the whole pipeline
--       call time_analysis('load_uniprot%');    # time the group of analyses dealing with loading Uniprot members
--       call time_analysis('mcl');              # time one specific analysis

DROP PROCEDURE IF EXISTS time_analysis;
CREATE PROCEDURE time_analysis(IN analyses_pattern CHAR(64))
READS SQL DATA
    SELECT
        COUNT(*)-COUNT(when_finished) AS still_running,
        (UNIX_TIMESTAMP(CASE WHEN COUNT(*)>COUNT(when_finished) THEN CURRENT_TIMESTAMP ELSE max(when_finished) END) - UNIX_TIMESTAMP(min(when_started)))/60 AS measured_in_minutes,
        (UNIX_TIMESTAMP(CASE WHEN COUNT(*)>COUNT(when_finished) THEN CURRENT_TIMESTAMP ELSE max(when_finished) END) - UNIX_TIMESTAMP(min(when_started)))/3600 AS measured_in_hours,
        (UNIX_TIMESTAMP(CASE WHEN COUNT(*)>COUNT(when_finished) THEN CURRENT_TIMESTAMP ELSE max(when_finished) END) - UNIX_TIMESTAMP(min(when_started)))/3600/24 AS measured_in_days
        FROM role JOIN analysis_base USING (analysis_id)
        WHERE logic_name LIKE analyses_pattern;


#### searches for a given string in job.input_id or analysis_data.data, and returns the  matching jobs.
#
# Thanks to Greg Jordan for the idea and the original version
#
# Usage:
#       call job_search('other_415');           # return all jobs whose input_id or analysis_data match the pattern

DROP PROCEDURE IF EXISTS job_search;
CREATE PROCEDURE job_search(IN srch CHAR(40))
READS SQL DATA
  SELECT
    a.analysis_id,
    a.logic_name,
    j.job_id AS job_id,
    j.status,
    j.retry_count,
    IFNULL(d.data, j.input_id) input_id
  FROM job j JOIN analysis_base a USING (analysis_id)
    LEFT JOIN analysis_data d ON j.input_id=concat('_ext_input_analysis_data_id ',d.analysis_data_id)
  WHERE j.input_id LIKE concat('%',srch,'%') OR d.data LIKE concat('%',srch,'%');


############## reset failed jobs for analysis #############################################
#
# Usage:
#       call reset_failed_jobs_for_analysis('load_uniprot');    # reset failed jobs of this particular analysis

DROP PROCEDURE IF EXISTS reset_failed_jobs_for_analysis;
CREATE PROCEDURE reset_failed_jobs_for_analysis(IN param_logic_name char(64))
MODIFIES SQL DATA
    UPDATE job j JOIN analysis_base a USING (analysis_id)
    SET j.status='READY', j.retry_count=0
    WHERE a.logic_name=param_logic_name
    AND   j.status='FAILED';


############## drop hive tables ###########################################################
#
# Usage:
#       call drop_hive_tables;      # just drop them all

DROP PROCEDURE IF EXISTS drop_hive_tables;
DELIMITER //
CREATE PROCEDURE drop_hive_tables()
MODIFIES SQL DATA
BEGIN
    SET FOREIGN_KEY_CHECKS=0;
    DROP VIEW IF EXISTS msg, progress, resource_usage_stats, live_roles, beekeeper_activity, semaphore_job;
    DROP TABLE IF EXISTS pipeline_wide_parameters, analysis_stats_monitor, worker_resource_usage, resource_description, analysis_data, job_file, dataflow_target, dataflow_rule, analysis_ctrl_rule, analysis_stats, log_message, accu, job, semaphore, role, worker, beekeeper, analysis_base, resource_class, hive_meta;
    SET FOREIGN_KEY_CHECKS=1;
END; //
DELIMITER ;
