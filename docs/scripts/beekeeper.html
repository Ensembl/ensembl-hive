<?xml version="1.0" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>beekeeper.pl</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link rev="made" href="mailto:root@localhost" />
</head>

<body>



<h1 id="NAME">NAME</h1>

<pre><code>    beekeeper.pl [options]</code></pre>

<h1 id="DESCRIPTION">DESCRIPTION</h1>

<pre><code>    The Beekeeper is in charge of interfacing between the Queen and a compute resource or &#39;compute farm&#39;.
    Its job is to initialize/sync the eHive database (via the Queen), query the Queen if it needs any workers
    and to send the requested number of workers to open machines via the runWorker.pl script.

    It is also responsible for interfacing with the Queen to identify workers which died
    unexpectedly so that she can free the dead workers and reclaim unfinished jobs.</code></pre>

<h1 id="USAGE-EXAMPLES">USAGE EXAMPLES</h1>

<pre><code>        # Usually run after the pipeline has been created to calculate the internal statistics necessary for eHive functioning
    beekeeper.pl -url mysql://username:secret@hostname:port/ehive_dbname -sync

        # Do not run any additional Workers, just check for the current status of the pipeline:
    beekeeper.pl -url mysql://username:secret@hostname:port/ehive_dbname

        # Run the pipeline in automatic mode (-loop), run all the workers locally (-meadow_type LOCAL) and allow for 3 parallel workers (-total_running_workers_max 3)
    beekeeper.pl -url mysql://username:secret@hostname:port/long_mult_test -meadow_type LOCAL -total_running_workers_max 3 -loop

        # Run in automatic mode, but only restrict to running blast-related analyses with the exception of analyses 4..6
    beekeeper.pl -url mysql://username:secret@hostname:port/long_mult_test -analyses_pattern &#39;blast%-4..6&#39; -loop

        # Restrict the normal execution to one iteration only - can be used for testing a newly set up pipeline
    beekeeper.pl -url mysql://username:secret@hostname:port/long_mult_test -run

        # Reset failed &#39;buggy_analysis&#39; jobs to &#39;READY&#39; state, so that they can be run again
    beekeeper.pl -url mysql://username:secret@hostname:port/long_mult_test -analyses_pattern buggy_analysis -reset_failed_jobs

        # Do a cleanup: find and bury dead workers, reclaim their jobs
    beekeeper.pl -url mysql://username:secret@hostname:port/long_mult_test -dead</code></pre>

<h1 id="OPTIONS">OPTIONS</h1>

<h2 id="Connection-parameters">Connection parameters</h2>

<pre><code>    -reg_conf &lt;path&gt;       : path to a Registry configuration file
    -reg_type &lt;string&gt;     : type of the registry entry (&#39;hive&#39;, &#39;core&#39;, &#39;compara&#39;, etc. - defaults to &#39;hive&#39;)
    -reg_alias &lt;string&gt;    : species/alias name for the Hive DBAdaptor
    -url &lt;url string&gt;      : url defining where hive database is located
    -nosqlvc &lt;0|1&gt;         : skip sql version check if 1</code></pre>

<h2 id="Configs-overriding">Configs overriding</h2>

<pre><code>    -config_file &lt;string&gt;  : json file (with absolute path) to override the default configurations (could be multiple)</code></pre>

<h2 id="Looping-control">Looping control</h2>

<pre><code>    -loop                  : run autonomously, loops and sleeps
    -max_loops &lt;num&gt;       : perform max this # of loops in autonomous mode
    -keep_alive            : do not stop when there are no more jobs to do - carry on looping
    -job_id &lt;job_id&gt;       : run 1 iteration for this job_id
    -run                   : run 1 iteration of automation loop
    -sleep &lt;num&gt;           : when looping, sleep &lt;num&gt; minutes (default 1 min)</code></pre>

<h2 id="Current-Meadow-control">Current Meadow control</h2>

<pre><code>    -meadow_type &lt;string&gt;               : the desired Meadow class name, such as &#39;LSF&#39; or &#39;LOCAL&#39;
    -total_running_workers_max &lt;num&gt;    : max # workers to be running in parallel
    -submit_workers_max &lt;num&gt;           : max # workers to create per loop iteration
    -submission_options &lt;string&gt;        : passes &lt;string&gt; to the Meadow submission command as &lt;options&gt; (formerly lsf_options)
    -submit_log_dir &lt;dir&gt;               : record submission output+error streams into files under the given directory (to see why some workers fail after submission)</code></pre>

<h2 id="Worker-control">Worker control</h2>

<pre><code>    -analyses_pattern &lt;string&gt;  : restrict the sync operation, printing of stats or looping of the beekeeper to the specified subset of analyses
    -can_respecialize &lt;0|1&gt;     : allow workers to re-specialize into another analysis (within resource_class) after their previous analysis was exhausted
    -force                      : run all workers with -force (see runWorker.pl)
    -killworker &lt;worker_id&gt;     : kill worker by worker_id
    -life_span &lt;num&gt;            : number of minutes each worker is allowed to run
    -job_limit &lt;num&gt;            : #jobs to run before worker can die naturally
    -retry_throwing_jobs &lt;0|1&gt;  : if a job dies *knowingly*, should we retry it by default?
    -hive_log_dir &lt;path&gt;        : directory where stdout/stderr of the hive is redirected
    -debug &lt;debug_level&gt;        : set debug level of the workers</code></pre>

<h2 id="Other-commands-options">Other commands/options</h2>

<pre><code>    -help                  : print this help
    -versions              : report both Hive code version and Hive database schema version
    -dead                  : detect all unaccounted dead workers and reset their jobs for resubmission
    -sync                  : re-synchronize the hive
    -unkwn                 : detect all workers in UNKWN state and reset their jobs for resubmission (careful, they *may* reincarnate!)
    -alldead               : tell the database all workers are dead (no checks are performed in this mode, so be very careful!)
    -balance_semaphores    : set all semaphore_counts to the numbers of unDONE fan jobs (emergency use only)
    -worker_stats          : show status of each running worker
    -failed_jobs           : show all failed jobs
    -job_output &lt;job_id&gt;   : print details for one job
    -reset_job_id &lt;num&gt;    : reset a job back to READY so it can be rerun
    -reset_failed_jobs     : reset FAILED jobs of analyses matching -analyses_pattern back to READY so they can be rerun
    -reset_all_jobs        : reset ALL jobs of analyses matching -analyses_pattern back to READY so they can be rerun</code></pre>

<h1 id="LICENSE">LICENSE</h1>

<pre><code>    Copyright [1999-2015] Wellcome Trust Sanger Institute and the EMBL-European Bioinformatics Institute
    Copyright [2016-2021] EMBL-European Bioinformatics Institute

    Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

         http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software distributed under the License
    is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and limitations under the License.</code></pre>

<h1 id="CONTACT">CONTACT</h1>

<pre><code>    Please subscribe to the Hive mailing list:  http://listserver.ebi.ac.uk/mailman/listinfo/ehive-users  to discuss Hive-related questions or to be notified of our updates</code></pre>


</body>

</html>


