## Configuration file for the long multiplication semaphored pipeline example
#
## Run it like this:
#
# init_pipeline.pl -conf long_mult_sema_pipeline.conf
# 

    # code directories:
my $ensembl_cvs_root_dir      = $ENV{'HOME'}.'/work';
#my $ensembl_cvs_root_dir      = $ENV{'HOME'}.'/ensembl_main'; ## for some Compara developers

    # long multiplication pipeline database connection parameters:
my $pipeline_db = {
    -host   => 'compara2',
    -port   => 3306,
    -user   => 'ensadmin',
    -pass   => 'ensembl',
    -dbname => $ENV{USER}.'_long_mult_sema_pipeline',
};

sub dbconn_2_mysql {
    my ($db_conn, $with_db) = @_;

    return "--host=$db_conn->{-host} --port=$db_conn->{-port} "
          ."--user=$db_conn->{-user} --pass=$db_conn->{-pass} "
          .($with_db ? $db_conn->{-dbname} : '');
} 

return {
        # pass connection parameters into the pipeline initialization script to create adaptors:
    -pipeline_db => $pipeline_db,

        # shell commands that create and possibly pre-fill the pipeline database:
    -pipeline_create_commands => [
        'mysql '.dbconn_2_mysql($pipeline_db, 0)." -e 'CREATE DATABASE $pipeline_db->{-dbname}'",

            # standard eHive tables and procedures:
        'mysql '.dbconn_2_mysql($pipeline_db, 1)." <$ensembl_cvs_root_dir/ensembl-hive/sql/tables.sql",
        'mysql '.dbconn_2_mysql($pipeline_db, 1)." <$ensembl_cvs_root_dir/ensembl-hive/sql/procedures.sql",

            # additional tables needed for long multiplication pipeline's operation:
        'mysql '.dbconn_2_mysql($pipeline_db, 1)." -e 'CREATE TABLE intermediate_result (a_multiplier char(40) NOT NULL, digit tinyint NOT NULL, result char(41) NOT NULL, PRIMARY KEY (a_multiplier, digit))'",
        'mysql '.dbconn_2_mysql($pipeline_db, 1)." -e 'CREATE TABLE final_result (a_multiplier char(40) NOT NULL, b_multiplier char(40) NOT NULL, result char(80) NOT NULL, PRIMARY KEY (a_multiplier, b_multiplier))'",

            # name the pipeline to differentiate the submitted processes:
        'mysql '.dbconn_2_mysql($pipeline_db, 1)." -e 'INSERT INTO meta (meta_key, meta_value) VALUES (\"name\", \"slmult\")'",
    ],

    -pipeline_analyses => [
        {   -logic_name => 'sema_start',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::LongMult::SemaStart',
            -parameters => {},
            -input_ids => [
                { 'a_multiplier' => '9650516169', 'b_multiplier' => '327358788' },
                { 'a_multiplier' => '327358788', 'b_multiplier' => '9650516169' },
            ],
            -flow_into => {
                1 => [ 'add_together'  ],   # will create a semaphored funnel job to wait for the fan to complete and add the results
                2 => [ 'part_multiply' ],   # will create a fan of jobs that control the semaphored funnel
            },
        },

        {   -logic_name    => 'part_multiply',
            -module        => 'Bio::EnsEMBL::Hive::RunnableDB::LongMult::PartMultiply',
            -parameters    => {},
            -input_ids     => [
                # (jobs for this analysis will be flown_into via branch-2 from 'start' jobs above)
            ],
        },
        
        {   -logic_name => 'add_together',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::LongMult::AddTogether',
            -parameters => {},
            -input_ids => [
                # (jobs for this analysis will be flown_into via branch-1 from 'start' jobs above)
            ],
            # jobs in this analyses are semaphored, so no need to '-wait_for'
        },
    ],
};

